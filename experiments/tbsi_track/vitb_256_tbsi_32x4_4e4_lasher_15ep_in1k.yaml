DATA:
  MAX_SAMPLE_INTERVAL: 200
  MEAN:
  - 0.485
  - 0.456
  - 0.406
  - 0.449
  - 0.449
  - 0.449
  SEARCH:
    CENTER_JITTER: 3
    FACTOR: 4.0
    SCALE_JITTER: 0.25
    SIZE: 256
    NUMBER: 1
  STD:
  - 0.229
  - 0.224
  - 0.225
  - 0.226
  - 0.226
  - 0.226
  TEMPLATE:
    CENTER_JITTER: 0
    FACTOR: 2.0
    SCALE_JITTER: 0
    SIZE: 128
  TRAIN:
    DATASETS_NAME:
      - LasHeR_train
    DATASETS_RATIO:
      - 1
    SAMPLE_PER_EPOCH: 60000
  VAL:
    DATASETS_NAME:
    - LasHeR_test
    DATASETS_RATIO:
    - 1
    SAMPLE_PER_EPOCH: 10000
MODEL:
  PRETRAIN_FILE: "deit_base_patch16_224-b5f2ef4d.pth"  # ImageNet-1k pretraining
  EXTRA_MERGER: False
  RETURN_INTER: False
  BACKBONE:
    TYPE: vit_base_patch16_224_tbsi
    STRIDE: 16
    TBSI_LOC: [3, 6, 9]
  HEAD:
    TYPE: CENTER
    NUM_CHANNELS: 256
TRAIN:
  BACKBONE_MULTIPLIER: 0.1
  DROP_PATH_RATE: 0.1
  TBSI_DROP_PATH: [0.0, 0.0, 0.0]  # Drop_path rate for TBSI layers
  SOT_PRETRAIN: False  # Use SOT datasets pretrained weight
  BATCH_SIZE: 32
  EPOCH: 15
  GIOU_WEIGHT: 2.0
  L1_WEIGHT: 5.0
  GRAD_CLIP_NORM: 0.1
  LR: 0.0004
  LR_DROP_EPOCH: 10
  NUM_WORKER: 8
  OPTIMIZER: ADAMW
  PRINT_INTERVAL: 50
  SCHEDULER:
    TYPE: step
    DECAY_RATE: 0.1
  VAL_EPOCH_INTERVAL: 10
  WEIGHT_DECAY: 0.0001
  AMP: True
TEST:
  EPOCH: 15
  SEARCH_FACTOR: 4.0
  SEARCH_SIZE: 256
  TEMPLATE_FACTOR: 2.0
  TEMPLATE_SIZE: 128
